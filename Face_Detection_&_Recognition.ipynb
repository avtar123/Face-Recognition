{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/avtar123/Face-Recognition/blob/main/Face_Detection_%26_Recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Mounting Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KeWmQC6EWO7z",
        "outputId": "9d139008-d03d-46bd-89bd-072a7c6a5dcf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Va466-l0qrox"
      },
      "outputs": [],
      "source": [
        "# Importing Packages\n",
        "import os\n",
        "import cv2\n",
        "import torch\n",
        "import pickle\n",
        "import imutils\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import svm\n",
        "from sklearn.svm import SVC\n",
        "from PIL import Image, ImageFilter\n",
        "from sklearn.pipeline import Pipeline\n",
        "import torchvision.models as models\n",
        "from sklearn.pipeline import make_pipeline\n",
        "import torchvision.transforms as transforms\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "#from sklearn.model_selection import train_test_split\n",
        "from moviepy.video.io.VideoFileClip import VideoFileClip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating directory of players\n",
        "crp_img_dir = \"/content/drive/MyDrive/Players_Face_data\"\n",
        "crp_img_dir1 = os.listdir(crp_img_dir)"
      ],
      "metadata": {
        "id": "fGVIwn4PvpE9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating Dictionary for Players\n",
        "player_names_dict = {}\n",
        "count = 0\n",
        "for player in crp_img_dir1:\n",
        "    player_names_dict.update({\"{}\".format(count):player})\n",
        "    count+=1\n",
        "print(player_names_dict)"
      ],
      "metadata": {
        "id": "C8eOT69KvYMv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af0a9d8c-43c6-4480-f0cf-596962b9cee1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'0': 'virat_kohli', '1': 'Rohit_Sharma', '2': 'Quinton_De_Kock'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_dict = {}\n",
        "count = 0\n",
        "for player_id in player_names_dict.keys():\n",
        "  class_dict[player_id] = count\n",
        "  count = count + 1\n",
        "class_dict\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bCa74-Ncze2m",
        "outputId": "cd3826c1-d181-492f-a496-aff873d44fc1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'0': 0, '1': 1, '2': 2}"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extracting features using HOG"
      ],
      "metadata": {
        "id": "gjh1p5-c6WM2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def hog_feature(img):\n",
        "  win_size = (64,64)\n",
        "  block_size = (16,16)\n",
        "  block_stride = (8,8)\n",
        "  cell_size = (8,8)\n",
        "  num_bins = 9\n",
        "  hog = cv2.HOGDescriptor(win_size,block_size,block_stride,cell_size,num_bins)\n",
        "  hog_features = hog.compute(img)\n",
        "  #hog_features = hog_features.flatten()\n",
        "  hog_features = np.array(hog_features).flatten()\n",
        "  #hog_img = hog_features.reshape(-1,num_bins)\n",
        "  scaler = StandardScaler()\n",
        "  hog_features_normalized = scaler.fit_transform(hog_features.reshape(-1,1))\n",
        "  return hog_features_normalized"
      ],
      "metadata": {
        "id": "TY7DuzvVdafO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, y_train, x_test, y_test = [], [], [], []\n",
        "min_len = 500\n",
        "for player_id, player_name in player_names_dict.items():\n",
        "    player_img_dir = os.path.join(crp_img_dir,player_name)\n",
        "    player_face_img_dir = os.listdir(player_img_dir)\n",
        "    #print(player_img_dir)\n",
        "    #print(player_face_img_dir)\n",
        "    len_dir = len(player_face_img_dir)\n",
        "    if min_len>len_dir:\n",
        "      min_len = len_dir\n",
        "print(min_len)\n",
        "for player_id, player_name in player_names_dict.items():\n",
        "  #print(celebrity_name,player_name)\n",
        "  player_img_dir = os.path.join(crp_img_dir,player_name)\n",
        "  player_face_img_dir = os.listdir(player_img_dir)\n",
        "  #print(player_img_dir)\n",
        "  #print(player_face_img_dir)\n",
        "  split_counter = 0\n",
        "  #for player_img in player_face_img_dir[:min_len]:\n",
        "  for player_img in player_face_img_dir:\n",
        "    #print(player_img)\n",
        "    img = cv2.imread(player_img_dir+\"/\"+player_img)\n",
        "    #print(img)\n",
        "    #gray_img = cv2.cvtColor( img,cv2.COLOR_RGB2GRAY )\n",
        "    #print(gray_img)\n",
        "    #cv2.imwrite(\"img.png\",gray_img)\n",
        "    #if gray_img is not None:\n",
        "    if img is not None:\n",
        "      #scaled_img = cv2.resize(gray_img, (100,100))\n",
        "      scaled_img = cv2.resize(img, (100,100))\n",
        "      #cv2.imwrite(\"img.png\",scaled_img)\n",
        "      hog_img = hog_feature(scaled_img)\n",
        "      #cv2.imwrite(\"img_1.png\",hog_img)\n",
        "      if split_counter<5:\n",
        "        x_test.append(hog_img)\n",
        "        y_test.append(class_dict[player_id])\n",
        "      else:\n",
        "        x_train.append(hog_img)\n",
        "        y_train.append(class_dict[player_id])\n",
        "      #break\n",
        "    split_counter+=1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MsTrzqHQ6R4K",
        "outputId": "700e90d9-0c5b-432a-dd58-dcb971fe0dce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "110\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extracting features using VGG"
      ],
      "metadata": {
        "id": "VWXh01HY6ikG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vgg16 = models.vgg16(pretrained=True)\n",
        "feature_extractor = torch.nn.Sequential(*list(vgg16.features.children())[:-1])\n",
        "transform = transforms.Compose([transforms.Resize((224,224)),transforms.ToTensor(),transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225])])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ktolFJIP5i74",
        "outputId": "7e865657-02a0-4a7a-a3b5-e6e4e1c68848"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:py.warnings:/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "\n",
            "WARNING:py.warnings:/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "\n",
            "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 528M/528M [00:05<00:00, 99.9MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, y_train, x_test, y_test = [], [], [], []\n",
        "min_len = 500\n",
        "for player_id, player_name in player_names_dict.items():\n",
        "    player_img_dir = os.path.join(crp_img_dir,player_name)\n",
        "    player_face_img_dir = os.listdir(player_img_dir)\n",
        "    #print(player_img_dir)\n",
        "    #print(player_face_img_dir)\n",
        "    len_dir = len(player_face_img_dir)\n",
        "    if min_len>len_dir:\n",
        "      min_len = len_dir\n",
        "print(min_len)\n",
        "for player_id, player_name in player_names_dict.items():\n",
        "  #print(celebrity_name,player_name)\n",
        "  player_img_dir = os.path.join(crp_img_dir,player_name)\n",
        "  player_face_img_dir = os.listdir(player_img_dir)\n",
        "  #print(player_img_dir)\n",
        "  #print(player_face_img_dir)\n",
        "  split_counter = 0\n",
        "  #for player_img in player_face_img_dir[:min_len]:\n",
        "  for player_img in player_face_img_dir:\n",
        "    #print(player_img)\n",
        "    #img = cv2.imread(player_img_dir+\"/\"+player_img)\n",
        "    img = Image.open(player_img_dir+\"/\"+player_img)\n",
        "    inp_img = transform(img).unsqueeze(0)\n",
        "    with torch.no_grad():\n",
        "      features = feature_extractor(inp_img)\n",
        "      numpy_features = features.numpy()\n",
        "    #print(img)\n",
        "\n",
        "\n",
        "    if features is not None:\n",
        "      #scaled_img = cv2.resize(gray_img, (64,64))\n",
        "      #scaled_img = cv2.resize(img, (64,64))\n",
        "      #cv2.imwrite(\"img.png\",scaled_img)\n",
        "      #cv2.imwrite(\"img_1.png\",hog_img)\n",
        "      if split_counter<5:\n",
        "        x_test.append(numpy_features)\n",
        "        y_test.append(class_dict[player_id])\n",
        "      else:\n",
        "        x_train.append(numpy_features)\n",
        "        y_train.append(class_dict[player_id])\n",
        "      #break\n",
        "    split_counter+=1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U97cJqLxz5qd",
        "outputId": "b8139c7a-fbfb-4c30-83e1-4967fc6061e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "130\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Checking shapes of features and converting them accordingly SVM criteria"
      ],
      "metadata": {
        "id": "26gaIJ81G2-Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train[0].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kbl3l7MsSrIX",
        "outputId": "4a24de8e-9039-44ea-a525-b776fd5b9df9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 512, 14, 14)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(x_train[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "okW7VFwzDhMY",
        "outputId": "1c6f42e0-9278-48d6-86d6-876306cc181d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'numpy.ndarray'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = np.array(x_train).reshape(len(x_train),-1)\n",
        "x_test = np.array(x_test).reshape(len(x_test),-1)"
      ],
      "metadata": {
        "id": "3SpvevRSmsL8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train[0].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BC6ajcXzGCZQ",
        "outputId": "5b329206-8a72-49c5-86a8-ac0d1c9a6569"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(100352,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bkCxXfYAD0J5",
        "outputId": "f1af922a-0fbb-4900-cf83-65d66dacf202"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.         0.         0.         ... 0.         0.         0.        ]\n",
            " [0.         0.         0.         ... 0.         0.         0.        ]\n",
            " [0.31122318 0.         0.         ... 3.3831255  0.         0.        ]\n",
            " ...\n",
            " [0.         0.         0.         ... 0.         0.         0.        ]\n",
            " [0.         0.         0.         ... 0.         0.         0.        ]\n",
            " [0.         0.         0.         ... 0.         0.         0.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_train)"
      ],
      "metadata": {
        "id": "3CI_SFL_M4Zs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9fe9871-eedc-425b-d716-2fdb85a5eb2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(x_train),len(y_train),len(x_test),len(y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "viiOW9NUQDgH",
        "outputId": "0bc26073-029d-42a0-c350-9a69321fb60c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "315 315 15 15\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Training**"
      ],
      "metadata": {
        "id": "5a-ERDXnuyBJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipe = Pipeline([('svc', SVC(kernel = 'poly', C = 10,gamma = \"auto\"))])\n",
        "#model = svm.SVC(kernel = 'rbf', C = 10)\n",
        "pipe.fit(x_train, y_train)\n",
        "pipe.score(x_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yG7Xh5dbYdDx",
        "outputId": "49b1ae86-8192-46b1-b6f8-16b468e08959"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6666666666666666"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Saving the hog feature model\n",
        "pickle.dump(pipe, open(\"/content/drive/MyDrive/Face_detect_recog_models/player_recognition__hog_model_73.sav\", 'wb'))"
      ],
      "metadata": {
        "id": "_z9rukPx01Sp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Saving the VGG feature model\n",
        "pickle.dump(pipe, open(\"/content/drive/MyDrive/Face_detect_recog_models/player_recognition__vgg_model_72.sav\", 'wb'))"
      ],
      "metadata": {
        "id": "ny8TYyxGEOgg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Prediction** ***on*** **image**"
      ],
      "metadata": {
        "id": "IKI1TrReutdx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Prediction using HOG features\n",
        "import hubconf\n",
        "model = hubconf._create(\"/content/drive/MyDrive/Face_detect_recog_models/face_detection_model.pt\")\n",
        "pre_img = cv2.imread(\"/content/rs_54.jfif\")\n",
        "results = np.array(model(pre_img).pred[0].cpu())\n",
        "results1= np.array(results[np.isin(results[:,5],np.array([0]))])\n",
        "if len(results)>0:\n",
        "  for i in results:\n",
        "    crop_face = pre_img[int(i[1]):int(i[3]),int(i[0]):int(i[2])]\n",
        "    img_rgb = cv2.cvtColor(crop_face,cv2.COLOR_BGR2RGB)\n",
        "    pre_gray_img = cv2.cvtColor( img_rgb,cv2.COLOR_RGB2GRAY )\n",
        "    scaled_pre_gray_img = cv2.resize(pre_gray_img, (100,100))\n",
        "    pre_hog_img = hog_feature(scaled_pre_gray_img)\n",
        "    pre_reshape_img = np.array(pre_hog_img).reshape(1,-1)"
      ],
      "metadata": {
        "id": "F2uQVmexsUPz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d0f5966-5b4e-473b-951d-da4ca7275f61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "YOLOv5 ðŸš€ v7.0-210-gdd10481 Python-3.10.12 torch-2.0.1+cu118 CPU\n",
            "\n",
            "Fusing layers... \n",
            "Model summary: 157 layers, 7012822 parameters, 0 gradients, 15.8 GFLOPs\n",
            "Adding AutoShape... \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Prediction using HOG features\n",
        "pre_img = cv2.imread(\"/content/rohit_sharma_1498.png\")\n",
        "scaled_pre_gray_img = cv2.resize(pre_gray_img, (100,100))\n",
        "pre_hog_img = hog_feature(scaled_pre_gray_img)\n",
        "pre_reshape_img = np.array(pre_hog_img).reshape(1,-1)"
      ],
      "metadata": {
        "id": "a_-uwE1A3DvN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Prediction using VGG\n",
        "img = Image.open(\"/content/virat_kohli_1803.png\")\n",
        "inp_img = transform(img).unsqueeze(0)\n",
        "with torch.no_grad():\n",
        "  features = feature_extractor(inp_img)\n",
        "  numpy_features = features.numpy()\n",
        "pre_reshape_img = np.array(numpy_features).reshape(1,-1)"
      ],
      "metadata": {
        "id": "U910YhiCIFAe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Predicting\n",
        "load_model = pickle.load(open(\"/content/drive/MyDrive/Face_detect_recog_models/player_recognition__VGG_model_66.sav\", 'rb'))\n",
        "result = load_model.predict(pre_reshape_img)"
      ],
      "metadata": {
        "id": "OEHeb9PksUiK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Name of Player Recognised\n",
        "player_names_dict[\"{}\".format(result[0])]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "hHw3Ykumxlb5",
        "outputId": "71c71743-0bc7-4487-dde1-4b5b252c99e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'virat_kohli'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Prediction** **on** **a** **video**"
      ],
      "metadata": {
        "id": "y0_g95oH_Vev"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/ultralytics/yolov5  # clone\n",
        "%cd yolov5\n",
        "%pip install -qr requirements.txt comet_ml  # install\n",
        "\n",
        "import torch\n",
        "import utils\n",
        "display = utils.notebook_init()  # checks"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vXARU9rAilSu",
        "outputId": "03ad1199-b888-40d3-95ad-08a696bd7657"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "YOLOv5 ðŸš€ v7.0-210-gdd10481 Python-3.10.12 torch-2.0.1+cu118 CPU\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setup complete âœ… (2 CPUs, 12.7 GB RAM, 27.0/107.7 GB disk)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vid = VideoFileClip(\"/content/drive/MyDrive/Video_data/PUNJAB-KINGS_ROYAL-CHALLENGERS-BANGALORE_20-04-2023_T20_1st_INNING_2_3_FOUR_Virat-Kohli.mp4\")\n",
        "os.chdir(\"/content/drive/MyDrive/Yolov5\")"
      ],
      "metadata": {
        "id": "es-4Y71EeiY9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def player_recog(img,face_recogniton_model,player_names_dict):\n",
        "\n",
        "    load_model = pickle.load(open(face_recogniton_model, 'rb'))\n",
        "    result = load_model.predict(img)\n",
        "    #result = pipe.predict(img)\n",
        "    return player_names_dict[\"{}\".format(result[0])]"
      ],
      "metadata": {
        "id": "3323Mg_zjATX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Predicting by HOG feature\n",
        "import hubconf\n",
        "model = hubconf._create(\"/content/drive/MyDrive/Face_detect_recog_models/face_detection_model.pt\")\n",
        "#player_name = os.listdir(\"/content/drive/MyDrive/Players_face_dataset\")\n",
        "for duration in range(0,int(vid.duration)):\n",
        "\n",
        "    frame = vid.get_frame(t = duration)\n",
        "    results = np.array(model(frame).pred[0].cpu())\n",
        "    results1= np.array(results[np.isin(results[:,5],np.array([0]))])\n",
        "    if len(results)>0:\n",
        "        for i in results:\n",
        "            crop_face = frame[int(i[1]):int(i[3]),int(i[0]):int(i[2])]\n",
        "            #print(crop_face)\n",
        "            img_rgb = cv2.cvtColor(crop_face,cv2.COLOR_BGR2RGB)\n",
        "            #gray_img = cv2.cvtColor( img_rgb,cv2.COLOR_RGB2GRAY )\n",
        "            scaled_gray_img = cv2.resize(img_rgb, (100,100))\n",
        "            hog_img = hog_feature(scaled_gray_img)\n",
        "            final_img = np.array(hog_img).reshape(1,-1)\n",
        "            Player_name = player_recog(final_img,\"/content/drive/MyDrive/Face_detect_recog_models/player_recognition__hog_model_66.sav\",player_names_dict)\n",
        "            print(duration,Player_name)"
      ],
      "metadata": {
        "id": "29xegqnyIRVY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Predicting by VGG feature\n",
        "import hubconf\n",
        "model = hubconf._create(\"/content/drive/MyDrive/Face_detect_recog_models/face_detection_model.pt\")\n",
        "#player_name = os.listdir(\"/content/drive/MyDrive/Players_face_dataset\")\n",
        "for duration in range(0,int(vid.duration)):\n",
        "\n",
        "    frame = vid.get_frame(t = duration)\n",
        "    results = np.array(model(frame).pred[0].cpu())\n",
        "    results1= np.array(results[np.isin(results[:,5],np.array([0]))])\n",
        "    if len(results)>0:\n",
        "        for i in results:\n",
        "            crop_face = frame[int(i[1]):int(i[3]),int(i[0]):int(i[2])]\n",
        "            img_rgb = cv2.cvtColor(crop_face,cv2.COLOR_BGR2RGB)\n",
        "            cv2.imwrite(\"/content/img.png\",img_rgb)\n",
        "            crop_img = Image.open(\"/content/img.png\")\n",
        "            inp_img = transform(crop_img).unsqueeze(0)\n",
        "            with torch.no_grad():\n",
        "              features = feature_extractor(inp_img)\n",
        "              numpy_features = features.numpy()\n",
        "            final_img = np.array(numpy_features).reshape(1,-1)\n",
        "            Player_name = player_recog(final_img,\"/content/drive/MyDrive/Face_detect_recog_models/player_recognition__VGG_model_66.sav\",player_names_dict)\n",
        "            print(duration,Player_name)\n",
        "            os.remove(\"/content/img.png\")"
      ],
      "metadata": {
        "id": "l-1RhpkF_URY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "023391bb-5f5b-4059-8bd1-abd35b7dd11a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "YOLOv5 ðŸš€ v7.0-210-gdd10481 Python-3.10.12 torch-2.0.1+cu118 CPU\n",
            "\n",
            "Fusing layers... \n",
            "Model summary: 157 layers, 7012822 parameters, 0 gradients, 15.8 GFLOPs\n",
            "Adding AutoShape... \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 Rohit_Sharma\n",
            "1 Rohit_Sharma\n",
            "2 Rohit_Sharma\n",
            "3 Rohit_Sharma\n",
            "6 Rohit_Sharma\n",
            "9 Rohit_Sharma\n",
            "10 Rohit_Sharma\n",
            "11 Rohit_Sharma\n",
            "11 Rohit_Sharma\n",
            "12 Rohit_Sharma\n",
            "13 Rohit_Sharma\n",
            "14 Rohit_Sharma\n",
            "15 Rohit_Sharma\n",
            "15 Rohit_Sharma\n",
            "15 Rohit_Sharma\n",
            "15 Rohit_Sharma\n",
            "15 Rohit_Sharma\n",
            "15 Rohit_Sharma\n",
            "15 Rohit_Sharma\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Augmenting** **Images**"
      ],
      "metadata": {
        "id": "cRaoy2pqKbnJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "count = 0\n",
        "for player_id, player_name in player_names_dict.items():\n",
        "  counter = 60\n",
        "  stopper = 1\n",
        "  total_img = 130\n",
        "  print(player_id,player_name)\n",
        "  player_img_dir = os.path.join(crp_img_dir,player_name)\n",
        "  player_face_img_dir = os.listdir(player_img_dir)\n",
        "  #print(player_img_dir)\n",
        "  #print(player_face_img_dir)\n",
        "  len_of_player_face_img_dir = len(player_face_img_dir)\n",
        "  print(\"No. of images in player's directory: \",len_of_player_face_img_dir)\n",
        "  req_img = total_img - len_of_player_face_img_dir\n",
        "  print(\"Required Images: \",req_img)\n",
        "  count+=1\n",
        "  if req_img==0:\n",
        "    print(\"No need to increase images!\")\n",
        "  else:\n",
        "    for player_img in player_face_img_dir:\n",
        "        #if stopper<10:\n",
        "        if stopper<=7 and stopper!=(req_img+1):\n",
        "          print(\"Stopper: \",stopper)\n",
        "          print(\"Enter in IF: \")\n",
        "          img = cv2.imread(player_img_dir+\"/\"+player_img)\n",
        "          #gray_img = cv2.cvtColor( img,cv2.COLOR_RGB2GRAY )\n",
        "          image = imutils.rotate(img, angle=165)\n",
        "          #image = cv2.rotate(img, cv2.ROTATE_180) # Try gray scale image with this property\n",
        "          #image = cv2.rotate(gray_img, cv2.ROTATE_90_CLOCKWISE)\n",
        "          cv2.imwrite(crp_img_dir+\"/\"+player_name+\"/Image_{}.png\".format(counter),image)\n",
        "          print(crp_img_dir+\"/\"+player_name+\"/img_{}.png\".format(counter))\n",
        "          counter+=1\n",
        "          stopper+=1\n",
        "        elif 5<stopper<=13 and stopper!=(req_img+1):\n",
        "          print(\"Stopper: \",stopper)\n",
        "          print(\"Enter in Elif: \")\n",
        "          img = cv2.imread(player_img_dir+\"/\"+player_img)\n",
        "          #gray_img = cv2.cvtColor( img,cv2.COLOR_RGB2GRAY )\n",
        "          image = imutils.rotate(img, angle=80)\n",
        "          #image = cv2.rotate(img, cv2.ROTATE_180) # Try gray scale image with this property\n",
        "          #image = cv2.rotate(gray_img, cv2.ROTATE_90_CLOCKWISE)\n",
        "          cv2.imwrite(crp_img_dir+\"/\"+player_name+\"/Image_{}.png\".format(counter),image)\n",
        "          print(crp_img_dir+\"/\"+player_name+\"/img_{}.png\".format(counter))\n",
        "          counter+=1\n",
        "          stopper+=1\n",
        "        elif stopper<=req_img:\n",
        "          print(\"Stopper: \",stopper)\n",
        "          print(\"Enter in Else: \")\n",
        "          img = cv2.imread(player_img_dir+\"/\"+player_img)\n",
        "          #gray_img = cv2.cvtColor( img,cv2.COLOR_RGB2GRAY )\n",
        "          image = imutils.rotate(img, angle=245)\n",
        "          #image = cv2.rotate(img, cv2.ROTATE_180) # Try gray scale image with this property\n",
        "          #image = cv2.rotate(gray_img, cv2.ROTATE_90_CLOCKWISE)\n",
        "          cv2.imwrite(crp_img_dir+\"/\"+player_name+\"/Image_{}.png\".format(counter),image)\n",
        "          print(crp_img_dir+\"/\"+player_name+\"/img_{}.png\".format(counter))\n",
        "          counter+=1\n",
        "          stopper+=1\n",
        "  # if count==2:\n",
        "  #   break\n"
      ],
      "metadata": {
        "id": "FfFpCpVRZcyn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e85b516e-96b3-4c7e-ef9a-286ffdc8d6ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 virat_kohli\n",
            "No. of images in player's directory:  110\n",
            "Required Images:  20\n",
            "Stopper:  1\n",
            "Enter in IF: \n",
            "/content/drive/MyDrive/Players_Face_data/virat_kohli/img_60.png\n",
            "Stopper:  2\n",
            "Enter in IF: \n",
            "/content/drive/MyDrive/Players_Face_data/virat_kohli/img_61.png\n",
            "Stopper:  3\n",
            "Enter in IF: \n",
            "/content/drive/MyDrive/Players_Face_data/virat_kohli/img_62.png\n",
            "Stopper:  4\n",
            "Enter in IF: \n",
            "/content/drive/MyDrive/Players_Face_data/virat_kohli/img_63.png\n",
            "Stopper:  5\n",
            "Enter in IF: \n",
            "/content/drive/MyDrive/Players_Face_data/virat_kohli/img_64.png\n",
            "Stopper:  6\n",
            "Enter in IF: \n",
            "/content/drive/MyDrive/Players_Face_data/virat_kohli/img_65.png\n",
            "Stopper:  7\n",
            "Enter in IF: \n",
            "/content/drive/MyDrive/Players_Face_data/virat_kohli/img_66.png\n",
            "Stopper:  8\n",
            "Enter in Elif: \n",
            "/content/drive/MyDrive/Players_Face_data/virat_kohli/img_67.png\n",
            "Stopper:  9\n",
            "Enter in Elif: \n",
            "/content/drive/MyDrive/Players_Face_data/virat_kohli/img_68.png\n",
            "Stopper:  10\n",
            "Enter in Elif: \n",
            "/content/drive/MyDrive/Players_Face_data/virat_kohli/img_69.png\n",
            "Stopper:  11\n",
            "Enter in Elif: \n",
            "/content/drive/MyDrive/Players_Face_data/virat_kohli/img_70.png\n",
            "Stopper:  12\n",
            "Enter in Elif: \n",
            "/content/drive/MyDrive/Players_Face_data/virat_kohli/img_71.png\n",
            "Stopper:  13\n",
            "Enter in Elif: \n",
            "/content/drive/MyDrive/Players_Face_data/virat_kohli/img_72.png\n",
            "Stopper:  14\n",
            "Enter in Else: \n",
            "/content/drive/MyDrive/Players_Face_data/virat_kohli/img_73.png\n",
            "Stopper:  15\n",
            "Enter in Else: \n",
            "/content/drive/MyDrive/Players_Face_data/virat_kohli/img_74.png\n",
            "Stopper:  16\n",
            "Enter in Else: \n",
            "/content/drive/MyDrive/Players_Face_data/virat_kohli/img_75.png\n",
            "Stopper:  17\n",
            "Enter in Else: \n",
            "/content/drive/MyDrive/Players_Face_data/virat_kohli/img_76.png\n",
            "Stopper:  18\n",
            "Enter in Else: \n",
            "/content/drive/MyDrive/Players_Face_data/virat_kohli/img_77.png\n",
            "Stopper:  19\n",
            "Enter in Else: \n",
            "/content/drive/MyDrive/Players_Face_data/virat_kohli/img_78.png\n",
            "Stopper:  20\n",
            "Enter in Else: \n",
            "/content/drive/MyDrive/Players_Face_data/virat_kohli/img_79.png\n",
            "1 Rohit_Sharma\n",
            "No. of images in player's directory:  110\n",
            "Required Images:  20\n",
            "Stopper:  1\n",
            "Enter in IF: \n",
            "/content/drive/MyDrive/Players_Face_data/Rohit_Sharma/img_60.png\n",
            "Stopper:  2\n",
            "Enter in IF: \n",
            "/content/drive/MyDrive/Players_Face_data/Rohit_Sharma/img_61.png\n",
            "Stopper:  3\n",
            "Enter in IF: \n",
            "/content/drive/MyDrive/Players_Face_data/Rohit_Sharma/img_62.png\n",
            "Stopper:  4\n",
            "Enter in IF: \n",
            "/content/drive/MyDrive/Players_Face_data/Rohit_Sharma/img_63.png\n",
            "Stopper:  5\n",
            "Enter in IF: \n",
            "/content/drive/MyDrive/Players_Face_data/Rohit_Sharma/img_64.png\n",
            "Stopper:  6\n",
            "Enter in IF: \n",
            "/content/drive/MyDrive/Players_Face_data/Rohit_Sharma/img_65.png\n",
            "Stopper:  7\n",
            "Enter in IF: \n",
            "/content/drive/MyDrive/Players_Face_data/Rohit_Sharma/img_66.png\n",
            "Stopper:  8\n",
            "Enter in Elif: \n",
            "/content/drive/MyDrive/Players_Face_data/Rohit_Sharma/img_67.png\n",
            "Stopper:  9\n",
            "Enter in Elif: \n",
            "/content/drive/MyDrive/Players_Face_data/Rohit_Sharma/img_68.png\n",
            "Stopper:  10\n",
            "Enter in Elif: \n",
            "/content/drive/MyDrive/Players_Face_data/Rohit_Sharma/img_69.png\n",
            "Stopper:  11\n",
            "Enter in Elif: \n",
            "/content/drive/MyDrive/Players_Face_data/Rohit_Sharma/img_70.png\n",
            "Stopper:  12\n",
            "Enter in Elif: \n",
            "/content/drive/MyDrive/Players_Face_data/Rohit_Sharma/img_71.png\n",
            "Stopper:  13\n",
            "Enter in Elif: \n",
            "/content/drive/MyDrive/Players_Face_data/Rohit_Sharma/img_72.png\n",
            "Stopper:  14\n",
            "Enter in Else: \n",
            "/content/drive/MyDrive/Players_Face_data/Rohit_Sharma/img_73.png\n",
            "Stopper:  15\n",
            "Enter in Else: \n",
            "/content/drive/MyDrive/Players_Face_data/Rohit_Sharma/img_74.png\n",
            "Stopper:  16\n",
            "Enter in Else: \n",
            "/content/drive/MyDrive/Players_Face_data/Rohit_Sharma/img_75.png\n",
            "Stopper:  17\n",
            "Enter in Else: \n",
            "/content/drive/MyDrive/Players_Face_data/Rohit_Sharma/img_76.png\n",
            "Stopper:  18\n",
            "Enter in Else: \n",
            "/content/drive/MyDrive/Players_Face_data/Rohit_Sharma/img_77.png\n",
            "Stopper:  19\n",
            "Enter in Else: \n",
            "/content/drive/MyDrive/Players_Face_data/Rohit_Sharma/img_78.png\n",
            "Stopper:  20\n",
            "Enter in Else: \n",
            "/content/drive/MyDrive/Players_Face_data/Rohit_Sharma/img_79.png\n",
            "2 Quinton_De_Kock\n",
            "No. of images in player's directory:  110\n",
            "Required Images:  20\n",
            "Stopper:  1\n",
            "Enter in IF: \n",
            "/content/drive/MyDrive/Players_Face_data/Quinton_De_Kock/img_60.png\n",
            "Stopper:  2\n",
            "Enter in IF: \n",
            "/content/drive/MyDrive/Players_Face_data/Quinton_De_Kock/img_61.png\n",
            "Stopper:  3\n",
            "Enter in IF: \n",
            "/content/drive/MyDrive/Players_Face_data/Quinton_De_Kock/img_62.png\n",
            "Stopper:  4\n",
            "Enter in IF: \n",
            "/content/drive/MyDrive/Players_Face_data/Quinton_De_Kock/img_63.png\n",
            "Stopper:  5\n",
            "Enter in IF: \n",
            "/content/drive/MyDrive/Players_Face_data/Quinton_De_Kock/img_64.png\n",
            "Stopper:  6\n",
            "Enter in IF: \n",
            "/content/drive/MyDrive/Players_Face_data/Quinton_De_Kock/img_65.png\n",
            "Stopper:  7\n",
            "Enter in IF: \n",
            "/content/drive/MyDrive/Players_Face_data/Quinton_De_Kock/img_66.png\n",
            "Stopper:  8\n",
            "Enter in Elif: \n",
            "/content/drive/MyDrive/Players_Face_data/Quinton_De_Kock/img_67.png\n",
            "Stopper:  9\n",
            "Enter in Elif: \n",
            "/content/drive/MyDrive/Players_Face_data/Quinton_De_Kock/img_68.png\n",
            "Stopper:  10\n",
            "Enter in Elif: \n",
            "/content/drive/MyDrive/Players_Face_data/Quinton_De_Kock/img_69.png\n",
            "Stopper:  11\n",
            "Enter in Elif: \n",
            "/content/drive/MyDrive/Players_Face_data/Quinton_De_Kock/img_70.png\n",
            "Stopper:  12\n",
            "Enter in Elif: \n",
            "/content/drive/MyDrive/Players_Face_data/Quinton_De_Kock/img_71.png\n",
            "Stopper:  13\n",
            "Enter in Elif: \n",
            "/content/drive/MyDrive/Players_Face_data/Quinton_De_Kock/img_72.png\n",
            "Stopper:  14\n",
            "Enter in Else: \n",
            "/content/drive/MyDrive/Players_Face_data/Quinton_De_Kock/img_73.png\n",
            "Stopper:  15\n",
            "Enter in Else: \n",
            "/content/drive/MyDrive/Players_Face_data/Quinton_De_Kock/img_74.png\n",
            "Stopper:  16\n",
            "Enter in Else: \n",
            "/content/drive/MyDrive/Players_Face_data/Quinton_De_Kock/img_75.png\n",
            "Stopper:  17\n",
            "Enter in Else: \n",
            "/content/drive/MyDrive/Players_Face_data/Quinton_De_Kock/img_76.png\n",
            "Stopper:  18\n",
            "Enter in Else: \n",
            "/content/drive/MyDrive/Players_Face_data/Quinton_De_Kock/img_77.png\n",
            "Stopper:  19\n",
            "Enter in Else: \n",
            "/content/drive/MyDrive/Players_Face_data/Quinton_De_Kock/img_78.png\n",
            "Stopper:  20\n",
            "Enter in Else: \n",
            "/content/drive/MyDrive/Players_Face_data/Quinton_De_Kock/img_79.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_params = {\n",
        "    'svm': {\n",
        "        'model': svm.SVC(gamma='auto',probability=True),\n",
        "        'params' : {\n",
        "            'svc__C': [1,10,100,1000],\n",
        "            'svc__kernel': ['rbf','linear','poly','sigmoid']\n",
        "        }\n",
        "    },\n",
        "    'random_forest': {\n",
        "        'model': RandomForestClassifier(),\n",
        "        'params' : {\n",
        "            'randomforestclassifier__n_estimators': [1,5,10]\n",
        "        }\n",
        "    },\n",
        "    'logistic_regression' : {\n",
        "        'model': LogisticRegression(solver='lbfgs',multi_class='auto'),\n",
        "        'params': {\n",
        "            'logisticregression__C': [1,5,10]\n",
        "        }\n",
        "    }\n",
        "}\n"
      ],
      "metadata": {
        "id": "SbFy_HivsLH0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Testing**"
      ],
      "metadata": {
        "id": "J0_kADvIhpEQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img1 = cv2.imread(\"/content/virat_kohli_1865.png\")\n",
        "print(img1.shape)\n",
        "image = cv2.resize(img1, (200,200))\n",
        "print(image.shape)\n",
        "cv2.imwrite(\"/content/img1.png\",image)"
      ],
      "metadata": {
        "id": "uVf_spav4Inw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "player_id = 0\n",
        "player_img_dir = []\n",
        "no_of_images_player = {}\n",
        "list_dir_path = os.listdir(dir_path)\n",
        "for player_name in list_dir_path:\n",
        "  player_img_dir.append(os.path.join(crp_img_dir,player_name))\n",
        "for player_image_dir in player_img_dir:\n",
        "  #print(player_image_dir)\n",
        "  player_images = os.listdir(player_image_dir)\n",
        "  #print(player_images)\n",
        "  no_of_images_of_player = len(player_images)\n",
        "  #print(no_of_images_of_player)\n",
        "  no_of_images_player.update({\"{}\".format(player_id):(no_of_images_of_player,player_image_dir.split(\"/\")[-1])})\n",
        "  #print(no_of_images_player)\n",
        "  player_id+=1\n",
        "  #break"
      ],
      "metadata": {
        "id": "zcr3bptThspI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "no_of_images_player"
      ],
      "metadata": {
        "id": "-BJYjPt4h9GI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scores = []\n",
        "best_estimators = {}\n",
        "for algo, mp in model_params.items():\n",
        "    pipe = make_pipeline(mp['model'])\n",
        "    clf =  GridSearchCV(pipe, mp['params'], cv=5, return_train_score=False)\n",
        "    clf.fit(x_train, y_train)\n",
        "    scores.append({\n",
        "        'model': algo,\n",
        "        'best_score': clf.best_score_,\n",
        "        'best_params': clf.best_params_\n",
        "    })\n",
        "    best_estimators[algo] = clf.best_estimator_\n",
        "\n",
        "df = pd.DataFrame(scores,columns=['model','best_score','best_params'])\n",
        "df"
      ],
      "metadata": {
        "id": "kKnAz98KsNP9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}